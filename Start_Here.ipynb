{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1de282-f9a0-452e-ae2b-82d63479a313",
   "metadata": {},
   "source": [
    "# Welcome to the Reinforcement Learning Project\n",
    "\n",
    "This notebook serves as a quick **guide and orientation** for anyone opening this repository for the first time.\n",
    "It explains what the project is about, how the files are organized, and how to get started running experiments in **JupyterLab**.\n",
    "\n",
    "By: Felipe Campoverde\n",
    "\n",
    "---\n",
    "\n",
    "# Project Overview\n",
    "\n",
    "Reinforcement Learning (RL) is a branch of Machine Learning that focuses on **how agents learn to make decisions** through interacting with an environment.\n",
    "The agent receives **rewards or penalties** based on its actions and gradually learns a policy that **maximizes cumulative reward** over time.\n",
    "\n",
    "In this project, the student implemented and compared several RL algorithms using a **custome GridWorld environment**:\n",
    "\n",
    "- **Q-Learning** - model-free, off-policy learning.\n",
    "- **SARSA** - model-free, on-policy learning.\n",
    "- **Dyna-Q** - model-based RL that blends learning and planning.\n",
    "\n",
    "Each algorithm is trained to navigate a **stochastic** grid world with obstacles, pits, and a goal state.\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Steup\n",
    "\n",
    "Before running notebooks, make sure your environment is active and functional:\n",
    "\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "If you have not yet installed dependencies:\n",
    "```bash\n",
    "# Preferable\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# In case 'requirements.txt' is not available\n",
    "pip install numpy scipy matplotlib jupyterlab ipykernel pandas tqdm \\\n",
    "            black ruff pytest pytest-cov mypy gymnasium pygame\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Repository Structure\n",
    "\n",
    "```text\n",
    "reinforcement_learning/\n",
    "├── 00_Start_Here.ipynb     ← you are here!\n",
    "├── notebooks/               ← main experiments\n",
    "│   ├── 01_q_learning.ipynb\n",
    "│   ├── 02_sarsa.ipynb\n",
    "│   └── 03_dyna_q.ipynb\n",
    "├── src/rl_capstone/         ← core implementation\n",
    "│   ├── gridworld.py\n",
    "│   ├── rl_algorithms.py\n",
    "│   └── utils.py\n",
    "├── data/                    ← training logs and results\n",
    "├── figs/                    ← generated plots\n",
    "├── reports/                 ← milestone & final reports\n",
    "├── tests/                   ← unit tests\n",
    "└── README.md                ← setup and project overview\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## How to Get Started\n",
    "\n",
    "1. Open the **Q-Learning notebook**:\n",
    "   \n",
    "- [notebooks/01_q_learning.ipynb](notebooks/01_q_learning.ipynb)\n",
    "\n",
    "2. Run all cells top-to-bottom (**Shift + Enter**) to train a Q-learning agent.\n",
    "\n",
    "3. Explore other algorithms:\n",
    "- [SARSA notebook](notebooks/02_sarsa.ipynb)\n",
    "- [Dyna-Q notebook](notebooks/03_dyna_q.ipynb)\n",
    "\n",
    "4. Compare results using plots saved under the **figs/** directory\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- All algorithm implementations live in the **src/rl_capstone/** folder.\n",
    "- The GridWorld environment defines states, transitions, and rewards.\n",
    "- You can modify hyperparameters (**alpha**, **gamma**, **epsilon**, etc) directly in each notebook to experiment.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "- Start with **Q-Learning** to understand the training loop.\n",
    "- Proceed to **SARSA** to compare on-policy learning.\n",
    "- Explore **Dyna-Q** to see how planning accelerates learning.\n",
    "- Document your results and insights in the **report/** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0d055-aa4a-472c-a644-83ce8bcbdd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gridrl)",
   "language": "python",
   "name": "gridrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
